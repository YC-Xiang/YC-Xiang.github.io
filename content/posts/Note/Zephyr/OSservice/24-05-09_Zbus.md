---
date: 2024-05-10T17:33:10+08:00
title: 'Zephyr -- Zbus'
tags:
- Zephyr
categories:
- Zephyr OS
---

https://docs.zephyrproject.org/latest/services/zbus/index.html
https://docs.zephyrproject.org/latest/samples/subsys/zbus/zbus.html
https://docs.zephyrproject.org/latest/samples/subsys/zbus/hello_world/README.html

# Concept

Zbus实现了一种线程间多对多的消息通信机制。

有三种类型的观察者：

- Listener，event dispatcher每次发布或通知通道时，都会执行的回调函数。是**同步**的。
- Subscriber，内部依赖于消息队列，event dispatcher每次发布或通知通道时，都会在其中放置更改的channel的引用。注意，这种观察者本身并不接收消息。收到通知后应从通道中读取消息。是**异步**的。
- Message subscribers，内部依赖于FIFO, event dispatcher每次发布或通知通道时，都会把一份copy的message放进FIFO。是**异步**的。

For example,在下图中，Timer是Channel Trigger的Publisher，Sensor Thread是Subscriber，Blink是Listener。
当timer发布message后，会执行Blink的回调函数来闪烁，Sensor thread可以获取sensor数据。
Sensor thread处理完数据后，又是Sensor data channel的publisher，发布message后，core thread接收到message，来处理sensor data。
Core thread处理完后，通知LoRa thread，在最后一个channel处理完成后，再次调用Blink的回调函数来闪烁。

![](https://xyc-1316422823.cos.ap-shanghai.myqcloud.com/20240510094937.png)

</br>

可以打开或关闭某个订阅者，某个订阅者也可以选择打开或关闭某个channel。

![](https://xyc-1316422823.cos.ap-shanghai.myqcloud.com/20240509165155.png)

# Virtual Distributed Event Dispatcher

假设一个场景，有一个channelA。T1为publisher，S1为Subscriber，L1,L2为Listener，MS1,MS2为Message Subscriber。

![](https://xyc-1316422823.cos.ap-shanghai.myqcloud.com/20240510092711.png)

The VDED execution总是发生在publisher's context, 基本流程为：

- 给channel上锁
- channel通过直接拷贝(memcpy)把new message拷贝过去。
- VDED执行listener的回调函数，把message拷贝给message subscriber，把channel reference加入到subscriber的notification message queue。Listener可以通过`zbus_chan_const_msg()`直接获取message的reference。
- 给channel解锁

如下图演示了执行流程，假设线程优先级为T1>MS1>MS2>S1：

![](https://xyc-1316422823.cos.ap-shanghai.myqcloud.com/20240510093044.png)

![](https://xyc-1316422823.cos.ap-shanghai.myqcloud.com/20240510093803.png)

可以看到Listener只直接引用channel里的message而不用拷贝，而Publisher会把message拷贝到Message subscriber。Subscriber则是当调度到的时候自己去拷贝message。

如果线程优先级为T1<MS1<MS2<S1:

![](https://xyc-1316422823.cos.ap-shanghai.myqcloud.com/20240510094611.png)

注意此时的执行顺序，在f时，T1发布message，会立刻调度到MS1, 在g时，会立刻调度到MS2。

## HLP priority boost

Zbus实现了自动提高publisher线程优先级的操作，选项为`CONFIG_ZBUS_PRIORITY_BOOST`，是默认自动打开的。这样能publisher线程不会像上面一样被打断，可以提高执行效率。

![](https://xyc-1316422823.cos.ap-shanghai.myqcloud.com/20240510101623.png)

为了使用该特性，需要将observer attach到一个线程：

```c
ZBUS_SUBSCRIBER_DEFINE(s1, 4);
void s1_thread(void *ptr1, void *ptr2, void *ptr3)
{
        const struct zbus_channel *chan;

        zbus_obs_attach_to_thread(&s1); // 将s1 attach到线程

        while (1) {
                zbus_sub_wait(&s1, &chan, K_FOREVER);

                /* Subscriber implementation */

        }
}
K_THREAD_DEFINE(s1_id, CONFIG_MAIN_STACK_SIZE, s1_thread, NULL, NULL, NULL, 2, 0, 0);
```

# Limitation

考虑到Zbus的benchmark，不适用于传输高速流数据。

密集字节流传输考虑用message queue和pipes。

ZBus使用network buffers，需要考虑CONFIG_ZBUS_MSG_SUBSCRIBER_NET_BUF_POOL_SIZE 和 CONFIG_HEAP_MEM_POOL_SIZE的大小

如果在Subscriber读取channel之前publisher发布两次message到channel，第二次的数据会覆盖第一次。 Subscriber会收到两个notifications，但读出来的都是第二个数据，导致数据丢失。

这个问题目前只能给subscriber足够的时间处理？不要过快publish channel。

# 源码分析

# 应用层

`samples/subsys/zbus/hello_world/`

首先需要定义传递的message type以及channel。

```c
// 第一个channel传递的message类型
struct version_msg {
	uint8_t major;
	uint8_t minor;
	uint16_t build;
};

// 第二个channel传递的message类型
struct acc_msg {
	int x;
	int y;
	int z;
};

// 定义第一个channel, 当publisher发布message到channel需要经过validator函数验证，这里为NULL。
ZBUS_CHAN_DEFINE(version_chan,       /* Name */
		 struct version_msg, /* Message type */
		 NULL,                 /* Validator */
		 NULL,                 /* User data */
		 ZBUS_OBSERVERS_EMPTY, /* observers */
		 ZBUS_MSG_INIT(.major = 0, .minor = 1,
			       .build = 2) /* Initial value major 0, minor 1, build 2 */
);

//定义第二个channel
ZBUS_CHAN_DEFINE(acc_data_chan,  /* Name */
		 struct acc_msg, /* Message type */
		 NULL,                                 /* Validator */
		 NULL,                                 /* User data */
		 ZBUS_OBSERVERS(foo_lis, bar_sub),     /* observers */
		 ZBUS_MSG_INIT(.x = 0, .y = 0, .z = 0) /* Initial value */
);
```

接着定义channel中observer的类型：

```c
ZBUS_LISTENER_DEFINE(foo_lis, listener_callback_example);
ZBUS_SUBSCRIBER_DEFINE(bar_sub, 4);
```

# 实现层

Publisher发布channel:

```c
int zbus_chan_pub(const struct zbus_channel *chan, const void *msg, k_timeout_t timeout)
{
	int err;

	if (k_is_in_isr()) { // 中断中需要立即publish message
		timeout = K_NO_WAIT;
	}

	//publish发布的限制时间
	k_timepoint_t end_time = sys_timepoint_calc(timeout);

	// 发布的message需要通过channel的validator函数
	if (chan->validator != NULL && !chan->validator(msg, chan->message_size)) {
		return -ENOMSG;
	}

	int context_priority = ZBUS_MIN_THREAD_PRIORITY;

	// 拷贝message到channel->message以及vded执行需要上锁，防止竞态
	err = chan_lock(chan, timeout, &context_priority);
	if (err) {
		return err;
	}
	// 拷贝数据
	memcpy(chan->message, msg, chan->message_size);
	//VDED开始执行，这个函数分析在下面
	err = _zbus_vded_exec(chan, end_time);

	chan_unlock(chan, context_priority);

	return err;
}
```

```c
_zbus_vded_exec(chan, end_time);
	// 通知这个channel的observers，根据不同类型执行不同流程。
	_zbus_notify_observer(chan, obs, end_time, buf);

static inline int _zbus_notify_observer(const struct zbus_channel *chan,
					const struct zbus_observer *obs, k_timepoint_t end_time,
					struct net_buf *buf)
{
	switch (obs->type) {
	// listener直接执行回调函数
	case ZBUS_OBSERVER_LISTENER_TYPE: {
		obs->callback(chan);
		break;
	}
	// subsriber是把channel的的地址传递到msgq中
	case ZBUS_OBSERVER_SUBSCRIBER_TYPE: {
		return k_msgq_put(obs->queue, &chan, sys_timepoint_timeout(end_time));
	}
#if defined(CONFIG_ZBUS_MSG_SUBSCRIBER)
	case ZBUS_OBSERVER_MSG_SUBSCRIBER_TYPE: {
		struct net_buf *cloned_buf = net_buf_clone(buf, sys_timepoint_timeout(end_time));
		// message subsriber是在这里直接把channel复制到buf中
		memcpy(net_buf_user_data(cloned_buf), &chan, sizeof(struct zbus_channel *));

		net_buf_put(obs->message_fifo, cloned_buf);

		break;
	}
#endif /* CONFIG_ZBUS_MSG_SUBSCRIBER */

	return 0;
	}
}
```

Observer接收channel：

```c
// subscriber接收线程：
static void subscriber_task(void)
{
	const struct zbus_channel *chan;

	while (!zbus_sub_wait(&bar_sub, &chan, K_FOREVER)) {
		struct acc_msg acc;

		if (&acc_data_chan == chan) {
			zbus_chan_read(&acc_data_chan, &acc, K_MSEC(500));
		}
	}
}

int zbus_sub_wait(const struct zbus_observer *sub, const struct zbus_channel **chan, k_timeout_t timeout)
{
	// 等待publisher发布channel
	return k_msgq_get(sub->queue, chan, timeout);
}

int zbus_chan_read(const struct zbus_channel *chan, void *msg, k_timeout_t timeout)
{
	if (k_is_in_isr()) {
		timeout = K_NO_WAIT;
	}

	int err = k_sem_take(&chan->data->sem, timeout);
	// 读出channel中保存的message
	memcpy(msg, chan->message, chan->message_size);

	k_sem_give(&chan->data->sem);

	return 0;
}
```
